{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94e6982",
   "metadata": {},
   "source": [
    "# Hands On: Seleksi Fitur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a24fd",
   "metadata": {},
   "source": [
    "Seringkali Anda akan memiliki ratusan atau ribuan fitur setelah berbagai penyandian dan pembuatan fitur. Hal ini dapat menyebabkan dua masalah. \n",
    "\n",
    "Pertama, semakin banyak fitur yang Anda miliki, semakin besar kemungkinan Anda menyesuaikan diri dengan set pelatihan dan validasi. Ini akan menyebabkan model Anda berkinerja lebih buruk dalam menggeneralisasi ke data baru.\n",
    "\n",
    "Kedua, semakin banyak fitur yang Anda miliki, semakin lama waktu yang dibutuhkan untuk melatih model Anda dan mengoptimalkan hyperparameter. Selain itu, saat membuat produk yang menghadap pengguna, Anda harus membuat inferensi secepat mungkin. Menggunakan lebih sedikit fitur dapat mempercepat inferensi dengan mengorbankan kinerja prediktif.\n",
    "\n",
    "Untuk membantu mengatasi masalah ini, Anda sebaiknya menggunakan teknik pemilihan fitur untuk mempertahankan fitur yang paling informatif untuk model Anda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8003b",
   "metadata": {},
   "source": [
    "Seleksi fitur (feature selection) adalah proses memilih feature yang tepat untuk melatih model ML. \n",
    "\n",
    "Untuk melakukan feature selection, kita perlu memahami hubungan antara variables.\n",
    "Hubungan antar dua random variables disebut correlation dan dapat dihitung dengan menggunakan correlation coefficient.\n",
    "\n",
    "Range nilai correlation coeficient adalah:\n",
    "\n",
    "Positif maks +1, korelasi positif, artinya kedua variable akan bergerak searah.\n",
    "Negatif maks -1, korelasi negatif, artinya kedua variable akan bergerak berlawanan.\n",
    "Nol, menunjukan antara kedua variable tidak ada correlation.\n",
    "Teknik perhitungan correlation cukup banyak, berikut yang umum digunakan: Pearson, Kendall dan Spearman.\n",
    "\n",
    "A. Pearson\n",
    "* Paling umum digunakan.\n",
    "* Digunakan untuk numerical data.\n",
    "* Tidak bisa digunakan untuk ordinal data.\n",
    "* Mengukur linear data dengan asumsi data terdistribusi normal.\n",
    "\n",
    "B. Kendall\n",
    "* Rank correlation measure.\n",
    "* Dapat digunakan untuk numerical dan ordinal data, namun tidak untuk nominal data.\n",
    "* Tidak diperlukan linear relationship antar variable.\n",
    "* Digunakan untuk mengukur kemiripan ranked ordering data.\n",
    "* Untuk kondisi normal lebih baik menggunakan Kendall dibandingkan Spearman.\n",
    "\n",
    "C. Spearman\n",
    "* Rank correlation measure\n",
    "* Dapat digunakan untuk numerical dan ordinal data, namun tidak untuk nominal data.\n",
    "* Tidak diperlukan linear relationship antar variable.\n",
    "* Monotonic relationship\n",
    "\n",
    "Ada beberapa metoda feature selection yang umum digunakan, yaitu Filter, Embedded dan Wrapper.\n",
    "\n",
    "**Filter Method**\n",
    "Umumnya digunakan pada tahap preprocessing. Pemilihan features tidak tergantung kepada algoritma ML yang akan digunakan . Features dipilih berdasarkan score test statistik kolerasi.\n",
    "\n",
    "**Embedded Method**\n",
    "Feature dipilih saat proses model training. Menggunakan learning algorithm untuk melakukan variable selection dan feature selection and classification secara simultan. Harus memilih algoritma machine learning yang sesuai.\n",
    "\n",
    "**Wrapper Method**\n",
    "Menggunakan subset of features untuk melatih model. Berdasarkan hasil yang dihasilkan dari model sebelumnya, kita tentukan untuk menambah atau membuang features dari subset. Kelemahannya membutuhkan resource besar dalam melakukan komputasi.\n",
    "\n",
    "Ada jenis seleksi fitur lainnya, seperti dalam slide modul 8 ini, diantaranya:\n",
    "1. Seleksi Univariat (Univariate Selection)\n",
    "2. Pentingnya Fitur (Feature Importance)\n",
    "3. Matriks Korelasi (Correlation Matrix) dengan Heatmap\n",
    "\n",
    "Teknik pemilihan fitur yang perlu kita ketahui, untuk mendapatkan performa terbaik dari model Anda.\n",
    "\n",
    "1. SelectKBest\n",
    "2. Regresi linier\n",
    "3. Random Forest\n",
    "4. XGBoost\n",
    "5. Penghapusan Fitur Rekursif\n",
    "6. Boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb966f",
   "metadata": {},
   "source": [
    "### Berikut ini adalah sebagian kecil dari metode/teknik dalam Seleksi Fitur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a056c61",
   "metadata": {},
   "source": [
    "#### Sumber dataset: \n",
    "---\n",
    "\n",
    "https://www.kaggle.com/iabhishekofficial/mobile-price-classification#train.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6575259c",
   "metadata": {},
   "source": [
    "#### Deskripsi variabel dari dataset:\n",
    "\n",
    "* battery_power: Total energy a battery can store in one time measured in mAh\n",
    "* blue: Has Bluetooth or not\n",
    "* clock_speed: the speed at which microprocessor executes instructions\n",
    "* dual_sim: Has dual sim support or not\n",
    "* fc: Front Camera megapixels\n",
    "* four_g: Has 4G or not\n",
    "* int_memory: Internal Memory in Gigabytes\n",
    "* m_dep: Mobile Depth in cm\n",
    "* mobile_wt: Weight of mobile phone\n",
    "* n_cores: Number of cores of the processor\n",
    "* pc: Primary Camera megapixels\n",
    "* px_height: Pixel Resolution Height\n",
    "* px_width: Pixel Resolution Width\n",
    "* ram: Random Access Memory in MegaBytes\n",
    "* sc_h: Screen Height of mobile in cm\n",
    "* sc_w: Screen Width of mobile in cm\n",
    "* talk_time: the longest time that a single battery charge will last when you are\n",
    "* three_g: Has 3G or not\n",
    "* touch_screen: Has touch screen or not\n",
    "* wifi: Has wifi or not\n",
    "* price_range: This is the target variable with a value of 0(low cost), 1(medium cost), 2(high cost) and 3(very high cost).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455ae5e",
   "metadata": {},
   "source": [
    "### 1. Seleksi Unvariate\n",
    "---\n",
    "Metode paling sederhana dan tercepat didasarkan pada uji statistik univariat. Untuk setiap fitur, ukur seberapa kuat target bergantung pada fitur menggunakan uji statistik seperti  Ï‡2 (chi-square) or ANOVA.\n",
    "\n",
    "Uji statistik dapat digunakan untuk memilih fitur-fitur tersebut yang memiliki relasi paling kuat dengan variabel output/target.\n",
    "Library scikit-learn menyediakan class *SelectKBest* yang digunakan untuk serangkaian uji statistik berbeda untuk memilih angka spesifik dari fitur. Berikut ini adalah uji statistik chi-square utk fitur non-negatif untuk memilih 10 fitur terbaik dari dataset *Mobile Price Range Prediction*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d9c7f8",
   "metadata": {},
   "source": [
    "link untuk belajar: https://machinelearningmastery.com/calculate-feature-importance-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10b71d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\alfen\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\alfen\\anaconda3\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\alfen\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from matplotlib) (20.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from matplotlib) (1.20.1)\n",
      "Requirement already satisfied: six in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ffb094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\alfen\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.20.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\alfen\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749080a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Specs          Score\n",
      "13            ram  931267.519053\n",
      "11      px_height   17363.569536\n",
      "0   battery_power   14129.866576\n",
      "12       px_width    9810.586750\n",
      "8       mobile_wt      95.972863\n",
      "6      int_memory      89.839124\n",
      "15           sc_w      16.480319\n",
      "16      talk_time      13.236400\n",
      "4              fc      10.135166\n",
      "14           sc_h       9.614878\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X = data.iloc[:,0:20]  #independent colums\n",
    "y = data.iloc[:,-1]    # target colum i.e price range\n",
    "\n",
    "# apply SelectKBest class to extract\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17648005",
   "metadata": {},
   "source": [
    "### 2. Feature Importance\n",
    "---\n",
    "*Feature importance* mengacu pada kelas teknik untuk menetapkan skor ke fitur input ke model prediktif yang menunjukkan *importance* relatif dari setiap fitur saat membuat prediksi.\n",
    "\n",
    "Skor *Feature importance* dapat dihitung untuk masalah yang melibatkan prediksi nilai numerik, yang disebut regresi, dan masalah yang melibatkan prediksi label kelas, yang disebut klasifikasi.\n",
    "\n",
    "Skor berguna dan dapat digunakan dalam berbagai situasi dalam masalah pemodelan prediktif, seperti:\n",
    "\n",
    "* Lebih memahami data.\n",
    "* Lebih memahami model.\n",
    "* Mengurangi jumlah fitur input.\n",
    "* memberi  skor untuk setiap fitur data, semakin tinggi skor semakin penting atau relevan fitur tersebut terhadap variabel output\n",
    "\n",
    "inbuilt yang dilengkapi dengan Pengklasifikasi Berbasis Pohon (Tree Based Classifier), kami akan menggunakan Pengklasifikasi Pohon Ekstra untuk mengekstraksi 10 fitur teratas untuk kumpulan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37905c2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ee52cf6e9b3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m#independent columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m#target column i.e price range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "X = data.iloc[:,0:20]  #independent columns\n",
    "y = data.iloc[:,-1]    #target column i.e price range\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a01da9",
   "metadata": {},
   "source": [
    "### 3. Matriks Korelasi dengan Heatmap\n",
    "---\n",
    "\n",
    "* Korelasi menyatakan bagaimana fitur terkait satu sama lain atau variabel target.\n",
    "* Korelasi bisa positif (kenaikan satu nilai fitur meningkatkan nilai variabel target) atau negatif (kenaikan satu nilai fitur menurunkan nilai variabel target)\n",
    "* Heatmap memudahkan untuk mengidentifikasi fitur mana yang paling terkait dengan variabel target, kami akan memplot peta panas fitur yang berkorelasi menggunakan seaborn library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X = data.iloc[:,0:20]  #independent columns\n",
    "y = data.iloc[:,-1]    #target column i.e price range\n",
    "\n",
    "#get correlations of each features in dataset\n",
    "corrmat = data.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "#plot heat map\n",
    "g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a2b58f",
   "metadata": {},
   "source": [
    "### Matriks Korelasi dengan Heatmap (lanjutan)\n",
    "---\n",
    "\n",
    "\n",
    "* lihat pada baris terakhir yaitu price range, korelasi antara price range dengan fitur lain dimana ada relasi kuat dengan variabel  ram dan diikuti oleh var battery power ,  px height and px width.\n",
    "* sedangkan utk var clock_speed dan n_cores berkorelasi lemah dengan price range\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
